<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>MapReduce概述 - Big Data</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Big Data</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="mapreduce-概述"><a class="header" href="#mapreduce-概述">MapReduce 概述</a></h1>
<ul>
<li><a href="#mapreduce-%E5%AE%9A%E4%B9%89">MapReduce 定义</a></li>
<li><a href="#mapreduce-%E4%BC%98%E7%BC%BA%E7%82%B9">MapReduce 优缺点</a>
<ul>
<li><a href="#%E4%BC%98%E7%82%B9">优点</a></li>
<li><a href="#%E7%BC%BA%E7%82%B9">缺点</a></li>
</ul>
</li>
<li><a href="#mapreduce-%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3">MapReduce 核心编程思想</a></li>
<li><a href="#mapreduce-%E8%BF%9B%E7%A8%8B">MapReduce 进程</a></li>
<li><a href="#%E5%AE%98%E6%96%B9-wordcount-%E6%BA%90%E7%A0%81">官方 WordCount 源码</a></li>
<li><a href="#%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96%E7%B1%BB%E5%9E%8B">常用数据序列化类型</a></li>
<li><a href="#mapreduce-%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83">MapReduce 编程规范</a></li>
<li><a href="#wordcount-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D">WordCount 案例实操</a>
<ul>
<li><a href="#%E6%9C%AC%E5%9C%B0%E6%B5%8B%E8%AF%95">本地测试</a></li>
<li><a href="#wordcount-%E6%A1%88%E4%BE%8B-debug-%E8%B0%83%E8%AF%95">WordCount 案例 Debug 调试</a></li>
<li><a href="#%E6%8F%90%E4%BA%A4%E5%88%B0%E9%9B%86%E7%BE%A4%E6%B5%8B%E8%AF%95">提交到集群测试</a></li>
</ul>
</li>
</ul>
<h2 id="mapreduce-定义"><a class="header" href="#mapreduce-定义">MapReduce 定义</a></h2>
<p>MapReduce 是一个分布式运算程序的编程框架，是用户开发 “基于 Hadoop 的数据分析应用” 的核心框架。</p>
<p>MapReduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。</p>
<h2 id="mapreduce-优缺点"><a class="header" href="#mapreduce-优缺点">MapReduce 优缺点</a></h2>
<p><img src="https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img/20241102144435.png" alt="" /></p>
<h3 id="优点"><a class="header" href="#优点">优点</a></h3>
<p>1 ）MapReduce 易于编程</p>
<p>它简单的实现一些接口， 就可以完成一个分布式程序， 这个分布式程序可以分布到大量廉价的 PC 机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得 MapReduce 编程变得非常流行。</p>
<p>2 ） 良好的扩展性</p>
<p>当你的计算资源不能得到满足的时候， 你可以通过简单的增加机器来扩展它的计算能力。</p>
<p>3 ） 高容错性</p>
<p>MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上， 这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败， 而且这个过程不需要人工参与， 而完全是由 Hadoop 内部完成的。</p>
<p>4 ） 适合 PB 级以上海量数据的离线处理</p>
<p>可以实现上千台服务器集群并发工作，提供数据处理能力。</p>
<h3 id="缺点"><a class="header" href="#缺点">缺点</a></h3>
<p>1 ） 不擅长实时计算</p>
<p>MapReduce 无法像 MySQL 一样，在毫秒或者秒级内返回结果。</p>
<p>2 ） 不擅长流式计算</p>
<p>流式计算的输入数据是动态的， 而 MapReduce 的输入数据集是静态的， 不能动态变化。
这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。</p>
<p>3 ） 不擅长 DAG （有向无环图）计算</p>
<p>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce 并不是不能做， 而是使用后， 每个 MapReduce 作业的输出结果都会写入到磁盘，会造成大量的磁盘 IO，导致性能非常的低下。</p>
<h2 id="mapreduce-核心编程思想"><a class="header" href="#mapreduce-核心编程思想">MapReduce 核心编程思想</a></h2>
<p><img src="https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img/20241102144500.png" alt="" /></p>
<p>（1）分布式的运算程序往往需要分成至少 2 个阶段。</p>
<p>（2）第一个阶段的 MapTask 并发实例，完全并行运行，互不相干。</p>
<p>（3）第二个阶段的 ReduceTask 并发实例互不相干，但是他们的数据依赖于上一个阶段的所有 MapTask 并发实例的输出。</p>
<p>（4）MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果用户的业务逻辑非常复杂，那就只能多个 MapReduce 程序，串行运行。</p>
<p>总结：分析 WordCount 数据流走向深入理解 MapReduce 核心思想。</p>
<h2 id="mapreduce-进程"><a class="header" href="#mapreduce-进程">MapReduce 进程</a></h2>
<p>任务、job、MR 都表示任务。</p>
<p>一个完整的 MapReduce 程序在分布式运行时有三类实例进程：</p>
<p>（1）MrAppMaster：负责整个程序的过程调度及状态协调。</p>
<p>（2）MapTask：负责 Map 阶段的整个数据处理流程。</p>
<p>（3）ReduceTask：负责 Reduce 阶段的整个数据处理流程。</p>
<h2 id="官方-wordcount-源码"><a class="header" href="#官方-wordcount-源码">官方 WordCount 源码</a></h2>
<p>采用反编译工具反编译源码，发现 WordCount 案例有 Map 类、Reduce 类和驱动类，且数据的类型是 Hadoop 自身封装的序列化类型。</p>
<p>如何查看里面的代码程序呢？使用反编译工具 jd-gui</p>
<p><a href="https://blog.csdn.net/zlbdmm/article/details/104653823">java 反编译工具 jd-gui 下载与使用</a></p>
<p>查看 <code>hadoop-mapreduce-examples-3.3.6.jar</code> 得到如下的源代码：</p>
<pre><code class="language-java">/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.hadoop.examples;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

public class WordCount {

  public static class TokenizerMapper 
       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
    
    private final static IntWritable one = new IntWritable (1);
    private Text word = new Text ();
      
    public void map (Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer (value.toString ());
      while (itr.hasMoreTokens ()) {
        word.set (itr.nextToken ());
        context.write (word, one);
      }
    }
  }
  
  public static class IntSumReducer 
       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
    private IntWritable result = new IntWritable ();

    public void reduce (Text key, Iterable&lt;IntWritable&gt; values, 
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get ();
      }
      result.set (sum);
      context.write (key, result);
    }
  }

  public static void main (String [] args) throws Exception {
    Configuration conf = new Configuration ();
    String [] otherArgs = new GenericOptionsParser (conf, args).getRemainingArgs ();
    if (otherArgs.length &lt; 2) {
      System.err.println ("Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;");
      System.exit (2);
    }
    Job job = Job.getInstance (conf, "word count");
    job.setJarByClass (WordCount.class);
    job.setMapperClass (TokenizerMapper.class);
    job.setCombinerClass (IntSumReducer.class);
    job.setReducerClass (IntSumReducer.class);
    job.setOutputKeyClass (Text.class);
    job.setOutputValueClass (IntWritable.class);
    for (int i = 0; i &lt; otherArgs.length - 1; ++i) {
      FileInputFormat.addInputPath (job, new Path (otherArgs [i]));
    }
    FileOutputFormat.setOutputPath (job,
      new Path (otherArgs [otherArgs.length - 1]));
    System.exit (job.waitForCompletion (true) ? 0 : 1);
  }
}

</code></pre>
<h2 id="常用数据序列化类型"><a class="header" href="#常用数据序列化类型">常用数据序列化类型</a></h2>
<p><img src="https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img/20241102145930.png" alt="" /></p>
<div class="table-wrapper"><table><thead><tr><th>Java 类型</th><th>Hadoop Writable 类型</th></tr></thead><tbody>
<tr><td>Boolean</td><td>BooleanWritable</td></tr>
<tr><td>Byte</td><td>ByteWritable</td></tr>
<tr><td>Int</td><td>IntWritable</td></tr>
<tr><td>Float</td><td>FloatWritable</td></tr>
<tr><td>Long</td><td>LongWritable</td></tr>
<tr><td>Double</td><td>DoubleWritable</td></tr>
<tr><td>String</td><td>Text</td></tr>
<tr><td>Map</td><td>MapWritable</td></tr>
<tr><td>Array</td><td>ArrayWritable</td></tr>
<tr><td>Null</td><td>NullWritable</td></tr>
</tbody></table>
</div>
<h2 id="mapreduce-编程规范"><a class="header" href="#mapreduce-编程规范">MapReduce 编程规范</a></h2>
<p>用户编写的程序分成三个部分：Mapper、Reducer 和 Driver。</p>
<p>1．Mapper 阶段</p>
<p>（1）用户自定义的 Mapper 要继承自己的父类</p>
<pre><code class="language-java">public static class TokenizerMapper 
       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{}
</code></pre>
<p>（2）Mapper 的输入数据是 KV 对的形式（KV 的类型可自定义）</p>
<p>p.s. K 是这一行的首字符偏移量，V 是这一行的内容。</p>
<p>（3）Mapper 中的业务逻辑写在 map () 方法中</p>
<pre><code class="language-java">public void map (Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer (value.toString ());
      while (itr.hasMoreTokens ()) {
        word.set (itr.nextToken ());
        context.write (word, one);
      }
    }
</code></pre>
<p>（4）Mapper 的输出数据是 KV 对的形式（KV 的类型可自定义）</p>
<p>（5）map () 方法（MapTask 进程）对每一个 &lt; K,V &gt; 调用一次</p>
<p>2．Reducer 阶段</p>
<p>（1）用户自定义的 Reducer 要继承自己的父类</p>
<pre><code class="language-java">public static class IntSumReducer 
       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt;{}
</code></pre>
<p>（2）Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV</p>
<p>（3）Reducer 的业务逻辑写在 reduce () 方法中</p>
<pre><code class="language-java">public void reduce (Text key, Iterable&lt;IntWritable&gt; values, 
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get ();
      }
      result.set (sum);
      context.write (key, result);
    }
</code></pre>
<p>（4）ReduceTask 进程对每一组相同 k 的 &lt; k,v &gt; 组调用一次 reduce () 方法</p>
<p>3．Driver 阶段</p>
<p>相当于 YARN 集群的客户端，用于提交我们整个程序到 YARN 集群，提交的是封装了 MapReduce 程序相关运行参数的 job 对象</p>
<h2 id="wordcount-案例实操"><a class="header" href="#wordcount-案例实操">WordCount 案例实操</a></h2>
<h3 id="本地测试"><a class="header" href="#本地测试">本地测试</a></h3>
<p>1 ） 需求</p>
<p>在给定的文本文件中统计输出每一个单词出现的总次数，输出结果默认按照 utf-8 编码顺序排列</p>
<p>（1）输入数据</p>
<p>创建一个文件并写入想要测试的数据，例如：</p>
<pre><code>Avengers Avengers
DC DC
Mavel Mavel
Iron_Man
Captain_America
Thor
Hulk
Black_Widow
Hawkeye
Black_Panther
Spider_Man
Doctor_Strange
Ant_Man
Vision
Scarlet_Witch
Winter_Soldier
Loki
Star_Lord
Gamora
Rocket_Raccoon
Groot
</code></pre>
<p>（2）期望输出数据（涉及输入的排序问题）</p>
<pre><code>Ant_Man	1
Avengers	2
Black_Panther	1
Black_Widow	1
Captain_America	1
DC	2
Doctor_Strange	1
Gamora	1
Groot	1
Hawkeye	1
Hulk	1
Iron_Man	1
Loki	1
Mavel	2
Rocket_Raccoon	1
Scarlet_Witch	1
Spider_Man	1
Star_Lord	1
Thor	1
Vision	1
Winter_Soldier	1
</code></pre>
<p>2 ） 需求分析</p>
<p>按照 MapReduce 编程规范，分别编写 Mapper、Reducer、Driver 类。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img/20241102150832.png" alt="" /></p>
<p>3 ） 环境准备</p>
<p>（1）创建 maven 工程 MapReduceDemo</p>
<p>（2）在 pom.xml 文件中添加版本信息以及相关依赖</p>
<pre><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.TianHan&lt;/groupId&gt;
    &lt;artifactId&gt;wordcount&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;maven.compiler.source&gt;21&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;21&lt;/maven.compiler.target&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
            &lt;version&gt;3.3.6&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt;
            &lt;artifactId&gt;junit-jupiter-api&lt;/artifactId&gt;
            &lt;version&gt;5.11.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;version&gt;2.0.16&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
<p>（2）在项目的 src/main/resources 目录下，新建一个文件，命名为 “log4j.properties” 用于打印相关日志。在该文件中填入：</p>
<pre><code>log4j.rootLogger=INFO, stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=% d % p [% c] - % m% n
log4j.appender.logfile=org.apache.log4j.FileAppender
log4j.appender.logfile.File=target/spring.log
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout
log4j.appender.logfile.layout.ConversionPattern=% d % p [% c] - % m% n
</code></pre>
<p>（3）创建包 mapreduce.wordcount 然后创建三个类</p>
<p>4 ） 编写程序</p>
<p>（1）编写 Mapper 类</p>
<pre><code class="language-java">package com.TianHan.mapreduce.wordcount;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import java.io.IOException;

/**
 * KEYIN, map 阶段输入的 key 的类型：LongWritable
 * VALUEIN,map 阶段输入 value 类型：Text
 * KEYOUT,map 阶段输出的 Key 类型：Text
 * VALUEOUT,map 阶段输出的 value 类型：IntWritable
 */
public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private Text outK = new Text ();
    private IntWritable outV = new IntWritable (1);  //map 阶段不进行聚合

    @Override
    protected void map (LongWritable key, Text value, Context context) throws IOException, InterruptedException {

        // 1 获取一行
        //xxxxxx xxxxxx
        String line = value.toString ();

        // 2 切割 (取决于原始数据的中间分隔符)
        //xxxxxxx
        //xxxxxxx
        String [] words = line.split (" ");

        // 3 循环写出
        for (String word : words) {
            // 封装 outk
            outK.set (word);

            // 写出
            context.write (outK, outV);
        }
    }
}
</code></pre>
<p>（2）编写 Reducer 类</p>
<pre><code class="language-java">package com.TianHan.mapreduce.wordcount;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

/**
 * KEYIN, reduce 阶段输入的 key 的类型：Text
 * VALUEIN,reduce 阶段输入 value 类型：IntWritable
 * KEYOUT,reduce 阶段输出的 Key 类型：Text
 * VALUEOUT,reduce 阶段输出的 value 类型：IntWritable
 */
public class WordCountReducer extends Reducer&lt;Text, IntWritable,Text,IntWritable&gt; {
    private IntWritable outV = new IntWritable ();

    @Override
    protected void reduce (Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {

        int sum = 0;
        //xxxxxxx xxxxxxx -&gt;(xxxxxxx,1),(xxxxxxx,1)
        //xxxxxxx, (1,1)
        // 将 values 进行累加
        for (IntWritable value : values) {
            sum += value.get ();
        }

        outV.set (sum);

        // 写出
        context.write (key,outV);
    }
}
</code></pre>
<p>（3）编写 Driver 驱动类</p>
<pre><code class="language-java">package com.TianHan.mapreduce.wordcount;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

public class WordCountDriver {

    public static void main (String [] args) throws IOException, ClassNotFoundException, InterruptedException {

        // 1 获取 job
        Configuration conf = new Configuration ();
        Job job = Job.getInstance (conf);

        // 2 设置 jar 包路径
        job.setJarByClass (WordCountDriver.class);

        // 3 关联 mapper 和 reducer
        job.setMapperClass (WordCountMapper.class);
        job.setReducerClass (WordCountReducer.class);

        // 4 设置 map 输出的 kv 类型
        job.setMapOutputKeyClass (Text.class);
        job.setMapOutputValueClass (IntWritable.class);

        // 5 设置最终输出的 kV 类型
        job.setOutputKeyClass (Text.class);
        job.setOutputValueClass (IntWritable.class);

        // 6 设置输入路径和输出路径
        FileInputFormat.setInputPaths (job, new Path ("E:\\BigData\\hadoop\\input"));
        FileOutputFormat.setOutputPath (job, new Path ("E:\\BigData\\hadoop\\output"));

        // 7 提交 job
        boolean result = job.waitForCompletion (true);

        System.exit (result ? 0 : 1);
    }
}
</code></pre>
<p>5 ） 本地测试</p>
<p>（1）由于这里通过 Maven 安装了 hadoop-client，所以不需要配置 HADOOP_HOME 变量以及 Windows 运行依赖即可成功运行程序。</p>
<p>（2）在 IDEA 上运行程序</p>
<p>注意：此时如果再运行一遍，会报错。在 mapreduce 中，如果输出路径存在会报错。</p>
<h3 id="wordcount-案例-debug-调试"><a class="header" href="#wordcount-案例-debug-调试">WordCount 案例 Debug 调试</a></h3>
<p>在以下几个地方打好断点：Mapper 类中 map 函数第一行、开始 setup、结束 cleanup</p>
<p>通过调试可以更清楚的理解机制。至少三遍。</p>
<h3 id="提交到集群测试"><a class="header" href="#提交到集群测试">提交到集群测试</a></h3>
<p>刚刚上面的代码是在本地运行的，是通过下载了 hadoop 相关的依赖，运用本地模式运行的。</p>
<p>我们还需要把程序推送到生产环境（Linux 环境）中。</p>
<p>（1）用 Maven 打包，需要添加的打包插件依赖</p>
<p>将下面的代码放在之前配置的依赖后面（对应 pom.xml 文件）</p>
<pre><code class="language-xml">&lt;build&gt; 
    &lt;plugins&gt; 
        &lt;plugin&gt; 
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; 
            &lt;version&gt;3.6.1&lt;/version&gt; 
            &lt;configuration&gt; 
                &lt;source&gt;1.8&lt;/source&gt; 
                &lt;target&gt;1.8&lt;/target&gt; 
            &lt;/configuration&gt; 
        &lt;/plugin&gt; 
        &lt;plugin&gt; 
            &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; 
            &lt;configuration&gt; 
                &lt;descriptorRefs&gt; 
                    &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; 
                &lt;/descriptorRefs&gt; 
            &lt;/configuration&gt; 
            &lt;executions&gt; 
                &lt;execution&gt; 
                    &lt;id&gt;make-assembly&lt;/id&gt; 
                    &lt;phase&gt;package&lt;/phase&gt; 
                    &lt;goals&gt; 
                        &lt;goal&gt;single&lt;/goal&gt; 
                    &lt;/goals&gt; 
                &lt;/execution&gt; 
            &lt;/executions&gt; 
        &lt;/plugin&gt; 
    &lt;/plugins&gt; 
&lt;/build&gt; 
</code></pre>
<p><code>maven-compiler-plugin</code>：：打包但不带有所需 jar 包，jar 包小</p>
<p><code>maven-assembly-plugin</code>：打包并带有所需 jar 包，jar 包大</p>
<p>这需要根据需求使用。</p>
<p>（2）将程序打成 jar 包</p>
<p>打包完毕，生成 jar 包，去文件夹里查看一下</p>
<p>（3）修改不带依赖的 jar 包名称为 wc.jar，并拷贝该 jar 包到 Hadoop 集群的 /opt/module/hadoop-3.3.6 路径</p>
<p>思考：刚刚的程序中，我们写的路径是本地 Windows 系统中的路径，上传到 Linux 环境后它其实没有这个路径，输入输出路径不存在，于是我们需要对它进行修改，改成对应的集群路径。</p>
<p>如果想更灵活一点 —— 根据传入的路径来确定输入的路径，需要使用 <code>args [0]</code> 和 <code>args [1]</code></p>
<p>我们再创建一个 wordcount2 包，跟 wordcount 内容一致，就将输入输出路径修改了一下。</p>
<p>对于新改的程序，先点 clean 把前面的删掉，再点 package 进行打包。</p>
<p>将新的包按上面的操作更名 wc.jar</p>
<p>根据命令行设定输入输出路径，使用 <code>args [0]，args [1]</code>。</p>
<pre><code class="language-java">// 6 设置输入路径和输出路径
FileInputFormat.setInputPaths (job, new Path (args [0]));
FileOutputFormat.setOutputPath (job, new Path (args [1]));
</code></pre>
<p>（4）启动 Hadoop 集群</p>
<pre><code>start-dfs.sh
</code></pre>
<p>先在 HDFS 集群中设置刚刚要处理的源文件：</p>
<p>在集群中建一个 Marvel 文件夹，然后在文件夹中上传我们之前要处理的 Marvel.txt 源文件</p>
<p>（5）执行 WordCount 程序</p>
<p>生成 jar 包，导入 jar 包到集群，再重新运行程序</p>
<pre><code>hadoop jar wc.jar com.TianHan.mapreduce.wordcount.WordCountDriver mapreduce/input mapreduce/output
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="MapReduce.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="序列化.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="MapReduce.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="序列化.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
